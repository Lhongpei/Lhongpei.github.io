@misc{hajizadeh_linear_2023,
 abstract = {Recently, minimax optimization received renewed focus due to modern applications in machine learning, robust optimization, and reinforcement learning. The scale of these applications naturally leads to the use of ﬁrst-order methods. However, the nonconvexities and nonconcavities present in these problems, prevents the application of typical Gradient Descent-Ascent, which is known to diverge even in bilinear problems. Recently, it was shown that the Proximal Point Method (PPM) converges linearly for a family of nonconvex-nonconcave problems. In this paper, we study the convergence of a damped version of Extra-Gradient Method (EGM) which avoids potentially costly proximal computations, only relying on gradient evaluation. We show that EGM converges linearly for smooth minimax optimization problem satisfying the same nonconvex-nonconcave condition needed by PPM.},
 author = {Hajizadeh, Saeed and Lu, Haihao and Grimmer, Benjamin},
 file = {Hajizadeh 等 - 2023 - On the Linear Convergence of Extra-Gradient Method.pdf:C\:\\Users\\14532\\Zotero\\storage\\MXCREI2C\a̋jizadeh 等 - 2023 - On the Linear Convergence of Extra-Gradient Method.pdf:application/pdf},
 keywords = {Mathematics - Optimization and Control},
 language = {en},
 month = {March},
 note = {arXiv:2201.06167 [math]},
 publisher = {arXiv},
 title = {On the Linear Convergence of Extra-Gradient Methods for Nonconvex-Nonconcave Minimax Problems},
 url = {http://arxiv.org/abs/2201.06167},
 urldate = {2024-10-03},
 year = {2023}
}
