@misc{tassel_reinforcement_2021,
 abstract = {Scheduling is a fundamental task occurring in various automated systems applications, e.g., optimal schedules for machines on a job shop allow for a reduction of production costs and waste. Nevertheless, ﬁnding such schedules is often intractable and cannot be achieved by Combinatorial Optimization Problem (COP) methods within a given time limit. Recent advances of Deep Reinforcement Learning (DRL) in learning complex behavior enable new COP application possibilities. This paper presents an efﬁcient DRL environment for Job-Shop Scheduling – an important problem in the ﬁeld. Furthermore, we design a meaningful and compact state representation as well as a novel, simple dense reward function, closely related to the sparse make-span minimization criteria used by COP methods. We demonstrate that our approach signiﬁcantly outperforms existing DRL methods on classic benchmark instances, coming close to state-of-the-art COP approaches.},
 author = {Tassel, Pierre and Gebser, Martin and Schekotihin, Konstantin},
 file = {Tassel 等 - 2021 - A Reinforcement Learning Environment For Job-Shop .pdf:C\:\\Users\\14532\\Zotero\\storage\\66JU4IJY\\Tassel 等 - 2021 - A Reinforcement Learning Environment For Job-Shop .pdf:application/pdf},
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
 language = {en},
 month = {April},
 note = {arXiv:2104.03760 [cs]},
 publisher = {arXiv},
 title = {A Reinforcement Learning Environment For Job-Shop Scheduling},
 url = {http://arxiv.org/abs/2104.03760},
 urldate = {2024-07-04},
 year = {2021}
}
