---
title: A Reinforcement Learning Environment For Job-Shop Scheduling
authors:
- Pierre Tassel
- Martin Gebser
- Konstantin Schekotihin
date: '2021-04-01'
publishDate: '2024-11-04T04:02:22.589396Z'
publication_types:
- manuscript
publication: '*arXiv*'
abstract: Scheduling is a fundamental task occurring in various automated systems
  applications, e.g., optimal schedules for machines on a job shop allow for a reduction
  of production costs and waste. Nevertheless, ﬁnding such schedules is often intractable
  and cannot be achieved by Combinatorial Optimization Problem (COP) methods within
  a given time limit. Recent advances of Deep Reinforcement Learning (DRL) in learning
  complex behavior enable new COP application possibilities. This paper presents an
  efﬁcient DRL environment for Job-Shop Scheduling – an important problem in the ﬁeld.
  Furthermore, we design a meaningful and compact state representation as well as
  a novel, simple dense reward function, closely related to the sparse make-span minimization
  criteria used by COP methods. We demonstrate that our approach signiﬁcantly outperforms
  existing DRL methods on classic benchmark instances, coming close to state-of-the-art
  COP approaches.
tags:
- Computer Science - Artificial Intelligence
- Computer Science - Machine Learning
- Computer Science - Neural and Evolutionary Computing
links:
- name: URL
  url: http://arxiv.org/abs/2104.03760
---
