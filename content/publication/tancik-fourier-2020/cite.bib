@misc{tancik_fourier_2020,
 abstract = {We show that passing input points through a simple Fourier feature mapping enables a multilayer perceptron (MLP) to learn high-frequency functions in lowdimensional problem domains. These results shed light on recent advances in computer vision and graphics that achieve state-of-the-art results by using MLPs to represent complex 3D objects and scenes. Using tools from the neural tangent kernel (NTK) literature, we show that a standard MLP fails to learn high frequencies both in theory and in practice. To overcome this spectral bias, we use a Fourier feature mapping to transform the effective NTK into a stationary kernel with a tunable bandwidth. We suggest an approach for selecting problem-speciﬁc Fourier features that greatly improves the performance of MLPs for low-dimensional regression tasks relevant to the computer vision and graphics communities.},
 author = {Tancik, Matthew and Srinivasan, Pratul P. and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan T. and Ng, Ren},
 file = {Tancik 等 - 2020 - Fourier Features Let Networks Learn High Frequency.pdf:C\:\\Users\\14532\\Zotero\\storage\\66RSRUBF\\Tancik 等 - 2020 - Fourier Features Let Networks Learn High Frequency.pdf:application/pdf},
 keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
 language = {en},
 month = {June},
 note = {arXiv:2006.10739 [cs]},
 publisher = {arXiv},
 title = {Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains},
 url = {http://arxiv.org/abs/2006.10739},
 urldate = {2024-08-29},
 year = {2020}
}
